# Extending MCP Test Infrastructure for Resource Verification

**Date:** 2025-11-12
**Status:** üìã SPECIFICATION
**Related:** [05-fix-summary.md](./05-fix-summary.md)

## Executive Summary

This specification extends the current MCP test infrastructure (which validates 22 tools) to also verify MCP resources. The system currently has two independent testing approaches:

1. **`test_mcp.py`** - Primary integration test (stdio transport, Docker-based, used by `make test-scripts`)
2. **`mcp-test.py`** - Standalone HTTP endpoint tester (manual use, not integrated into main test flow)

Both use configuration generated by **`mcp-list.py`** (stored in `mcp-test.yaml`), but they operate independently. Currently, neither tests resources. This gap means resource endpoints, URI patterns, and content retrieval remain unvalidated in integration tests.

## Current State Analysis

### Existing Test Infrastructure

**Files Analyzed:**
1. **`scripts/tests/test_mcp.py`** (476 lines)
   - Manages Docker container lifecycle for stdio transport
   - Implements MCP protocol initialization sequence
   - Executes tool tests via JSON-RPC 2.0 over stdio
   - Filters tools by idempotence (read-only vs. write operations)
   - Provides Docker container management and cleanup

2. **`scripts/mcp-list.py`** (314 lines)
   - Extracts tool metadata by introspecting server code
   - **Already extracts resource metadata** (lines 70-109)
   - Generates CSV/JSON outputs with both tools and resources
   - Creates `mcp-test.yaml` configuration used by both test scripts
   - Uses `create_default_registry()` to access resources

3. **`scripts/mcp-test.py`** (247 lines)
   - **Independent** HTTP-based MCP endpoint testing client
   - **NOT called by `test_mcp.py`** despite outdated docstring
   - Requires external MCP server endpoint (no Docker management)
   - JSON-RPC request/response handling over HTTP
   - Tool calling and validation
   - SSE (Server-Sent Events) format support
   - **No resource testing capability**
   - Used for manual testing of running HTTP MCP servers

### Current Capabilities

**‚úÖ What Works:**
- Tool discovery and introspection
- Resource discovery and metadata extraction
- Tool testing via stdio transport (`test_mcp.py` - primary, integrated into CI)
- Tool testing via HTTP transport (`mcp-test.py` - standalone, manual use)
- Idempotent vs. non-idempotent filtering
- Docker container lifecycle management (stdio only)
- Protocol compliance (notifications/initialized fix)
- Shared YAML configuration (`mcp-test.yaml`) generated by `mcp-list.py`

**‚ùå What's Missing:**
- Resource testing in `test_mcp.py` (stdio transport - **primary gap**)
- Resource testing in `mcp-test.py` (HTTP transport - secondary, nice-to-have)
- Resource URI pattern validation
- Resource content verification
- Resource response schema validation
- Resource-specific test configuration in YAML (`test_resources` section)

### Resource System Overview

**From `mcp-list.py` analysis (lines 70-109):**

Resources are registered in a registry with:
- **URI Pattern:** Template for resource URIs (e.g., `quilt://status`)
- **Resource Class:** Implementation class name
- **Module:** Source module for the resource
- **Description:** First line of class docstring
- **Async Support:** Whether `_read_impl` is async
- **Handler Implementation:** Resource class handles read operations

**Example Resource from Code:**
```python
resources.append({
    "type": "resource",
    "name": uri_pattern,  # e.g., "quilt://status"
    "module": short_module,
    "signature": f"{resource_class.__name__}(uri='{uri_pattern}')",
    "description": doc.split('\n')[0],
    "is_async": is_async,
    "full_module_path": module_name,
    "handler_class": resource_class.__name__
})
```

## Problem Statement

### Why Resource Testing Matters

1. **API Surface Coverage**
   - Resources are first-class MCP primitives alongside tools
   - Resources provide data access, tools provide actions
   - Untested resources = incomplete integration testing

2. **URI Pattern Validation**
   - Resource URIs follow patterns (e.g., `quilt://status`, `quilt://config/{key}`)
   - URI routing must be validated
   - Pattern matching errors can break client access

3. **Content Contract Verification**
   - Resources return structured content (text, blob, JSON)
   - Schema validation ensures client compatibility
   - Breaking changes need detection

4. **Protocol Compliance**
   - Resources use `resources/read` method in MCP
   - Different protocol path than tools (`tools/call`)
   - Requires separate test implementation

### Current Testing Gap

**Tool Testing Flows:**

1. **Primary (CI/CD): `test_mcp.py` (stdio)**
   ```
   test_mcp.py ‚Üí Docker + stdio ‚Üí Initialize ‚Üí tools/call ‚Üí Validate Response
   ```

2. **Manual: `mcp-test.py` (HTTP)**
   ```
   mcp-test.py endpoint ‚Üí HTTP ‚Üí Initialize ‚Üí tools/call ‚Üí Validate Response
   ```

**Resource Testing Flows (Missing):**

1. **Primary Need: `test_mcp.py` (stdio)**
   ```
   test_mcp.py ‚Üí Docker + stdio ‚Üí Initialize ‚Üí resources/list ‚Üí resources/read ‚Üí Validate Content
   ```

2. **Secondary Nice-to-Have: `mcp-test.py` (HTTP)**
   ```
   mcp-test.py endpoint ‚Üí HTTP ‚Üí Initialize ‚Üí resources/list ‚Üí resources/read ‚Üí Validate Content
   ```

**Impact:**
- Zero resource integration test coverage
- No validation of resource URIs in CI/CD pipeline
- No verification of resource content
- Protocol compliance for resources unverified

## Requirements

### Functional Requirements

**FR1: Resource Discovery**
- List all available resources from server
- Validate resource URI patterns
- Verify resource metadata (name, description, MIME type)
- Compare discovered resources with expected registry

**FR2: Resource Reading**
- Read content from each resource URI
- Handle both static URIs (`quilt://status`) and templated URIs (`quilt://config/{key}`)
- Validate response format (text, blob, JSON)
- Verify MIME type matches declaration

**FR3: Resource Content Validation**
- Schema validation for structured content (JSON)
- Content format validation (text encoding, blob integrity)
- Required field presence checks
- Data type validation

**FR4: Test Configuration**
- Extend `mcp-test.yaml` with resource test cases
- Support URI template variable substitution
- Define expected content schemas
- Mark resources as idempotent (read-only) or not

**FR5: Error Handling**
- Validate error responses for invalid URIs
- Test missing resource handling
- Verify access denied scenarios
- Check malformed URI rejection

### Non-Functional Requirements

**NFR1: Performance**
- Resource tests complete within 2 minutes (same as tool tests)
- Parallel resource reading where possible
- Efficient Docker container reuse

**NFR2: Maintainability**
- Automatic resource discovery from code (no manual maintenance)
- Generated test configuration from introspection
- Clear test output with pass/fail status
- Verbose mode for debugging

**NFR3: Integration**
- Reuse existing Docker container infrastructure
- Use same stdio transport as tool tests
- Compatible with `make test-scripts` target
- Unified test report (tools + resources)

**NFR4: Documentation**
- Clear error messages for failures
- Test case documentation in YAML
- Usage examples and patterns
- Troubleshooting guide

## Design

### Architecture

**Primary Test System (CI/CD):**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PRIMARY: test_mcp.py                          ‚îÇ
‚îÇ              (Stdio transport, Docker-managed)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚îú‚îÄ‚îÄ‚îÄ Docker Container Lifecycle
                            ‚îÇ    ‚îú‚îÄ> Pull/start container
                            ‚îÇ    ‚îú‚îÄ> Stdio communication
                            ‚îÇ    ‚îî‚îÄ> Cleanup on exit
                            ‚îÇ
                            ‚îú‚îÄ‚îÄ‚îÄ Initialize MCP Session
                            ‚îÇ    ‚îî‚îÄ> notifications/initialized ‚úÖ
                            ‚îÇ
                            ‚îú‚îÄ‚îÄ‚îÄ Tool Testing (Existing)
                            ‚îÇ    ‚îú‚îÄ> tools/list
                            ‚îÇ    ‚îú‚îÄ> tools/call (x22)
                            ‚îÇ    ‚îî‚îÄ> Validate responses
                            ‚îÇ
                            ‚îî‚îÄ‚îÄ‚îÄ Resource Testing (NEW - PRIMARY FOCUS)
                                 ‚îú‚îÄ> resources/list
                                 ‚îú‚îÄ> resources/read (xN)
                                 ‚îî‚îÄ> Validate content
                                      ‚îú‚îÄ> Schema validation
                                      ‚îú‚îÄ> Content type checks
                                      ‚îî‚îÄ> URI pattern validation
```

**Secondary Test Tool (Manual):**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   SECONDARY: mcp-test.py                         ‚îÇ
‚îÇ        (HTTP transport, external server required)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚îú‚îÄ‚îÄ‚îÄ Connect to HTTP endpoint
                            ‚îÇ    ‚îî‚îÄ> User provides URL
                            ‚îÇ
                            ‚îú‚îÄ‚îÄ‚îÄ Initialize MCP Session
                            ‚îÇ
                            ‚îú‚îÄ‚îÄ‚îÄ Tool Testing (Existing)
                            ‚îÇ    ‚îî‚îÄ> Similar to test_mcp.py
                            ‚îÇ
                            ‚îî‚îÄ‚îÄ‚îÄ Resource Testing (NEW - NICE TO HAVE)
                                 ‚îî‚îÄ> Similar to test_mcp.py
```

**Shared Configuration:**
```
mcp-list.py ‚Üí mcp-test.yaml ‚Üí Used by both test_mcp.py and mcp-test.py
```

### Component Changes

#### 1. `scripts/mcp-list.py` Modifications

**Current State:** Already extracts resource metadata (lines 70-109)

**Changes Needed:**
```python
async def generate_test_yaml(server, output_file: str, env_vars: Dict[str, str]):
    """Generate mcp-test.yaml configuration with all available tools AND RESOURCES."""

    # Existing tool configuration (lines 159-246) - keep as-is

    # NEW: Add resource test configuration
    test_config["test_resources"] = {}

    # Get all registered resources
    registry = create_default_registry()
    for resource in registry._resources:
        uri_pattern = resource.uri_pattern
        resource_class = resource.__class__
        doc = inspect.getdoc(resource_class) or "No description available"

        # Build basic test case structure
        test_case = {
            "description": doc.split('\n')[0],
            "idempotent": True,  # Resources are generally read-only
            "uri": uri_pattern,
            "uri_variables": {},  # For templated URIs
            "expected_mime_type": "text/plain",  # Default, can be overridden
            "content_validation": {
                "type": "text",  # or "json", "blob"
                "min_length": 1,
                "max_length": 10000,
                "schema": None  # JSON schema if type=json
            }
        }

        # Detect URI template variables
        if "{" in uri_pattern:
            # Extract variable names from pattern
            # e.g., "quilt://config/{key}" -> variables: {"key": "default_value"}
            import re
            variables = re.findall(r'\{(\w+)\}', uri_pattern)
            for var in variables:
                test_case["uri_variables"][var] = f"CONFIGURE_{var.upper()}"

        # Infer content type from resource class or module
        if "json" in resource_class.__name__.lower():
            test_case["content_validation"]["type"] = "json"
            test_case["expected_mime_type"] = "application/json"

        test_config["test_resources"][uri_pattern] = test_case

    # Write YAML with tools AND resources
    with open(output_file, 'w', encoding='utf-8') as f:
        yaml.dump(test_config, f, ...)
```

**Key Points:**
- Reuse existing resource extraction code
- Add `test_resources` section to YAML config
- Detect URI template variables automatically
- Provide sensible defaults for validation
- Mark unconfigured variables for manual setup

#### 2. `scripts/tests/test_mcp.py` Additions

**New Function: `run_resource_tests_stdio()`**

```python
def run_resource_tests_stdio(
    server: DockerMCPServer,
    config_path: Path,
    resources: Optional[list[str]] = None,
    verbose: bool = False
) -> bool:
    """Run MCP resource tests using stdio transport.

    Args:
        server: Running Docker MCP server instance
        config_path: Path to mcp-test.yaml configuration
        resources: Optional list of resource URIs to test (None = all)
        verbose: Enable verbose output

    Returns:
        True if all resource tests passed, False otherwise
    """
    import json

    print(f"\nüóÇÔ∏è  Running MCP resource tests (stdio)...")
    print(f"   Config: {config_path}")

    if not server.process or server.process.poll() is not None:
        print("‚ùå Server process not running")
        return False

    try:
        # Load test configuration
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)

        test_resources = config.get("test_resources", {})
        if resources:
            test_resources = {k: v for k, v in test_resources.items() if k in resources}

        if not test_resources:
            print("‚ö†Ô∏è  No resources configured for testing")
            return True

        # First, list all available resources
        list_request = {
            "jsonrpc": "2.0",
            "id": 1,
            "method": "resources/list",
            "params": {}
        }

        server.process.stdin.write(json.dumps(list_request) + "\n")
        server.process.stdin.flush()
        response = server.process.stdout.readline()

        if verbose:
            print(f"resources/list response: {response[:200]}")

        if not response or "error" in response:
            print(f"‚ùå resources/list failed: {response}")
            return False

        available_resources = json.loads(response).get("result", {}).get("resources", [])
        available_uris = {r["uri"] for r in available_resources}

        print(f"üìã Server provides {len(available_resources)} resources")
        if verbose:
            for uri in sorted(available_uris):
                print(f"   - {uri}")

        # Test each resource
        success_count = 0
        fail_count = 0
        request_id = 2

        for uri_pattern, test_config in test_resources.items():
            try:
                start_time = time.time()

                # Substitute URI variables if needed
                uri = uri_pattern
                uri_vars = test_config.get("uri_variables", {})
                for var_name, var_value in uri_vars.items():
                    if var_value.startswith("CONFIGURE_"):
                        print(f"  ‚ö†Ô∏è  {uri_pattern}: Skipped (needs configuration: {var_name})")
                        continue
                    uri = uri.replace(f"{{{var_name}}}", var_value)

                # Check if resource exists
                if uri not in available_uris:
                    fail_count += 1
                    print(f"  ‚ùå {uri}: Resource not found in server")
                    continue

                # Read the resource
                read_request = {
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "method": "resources/read",
                    "params": {
                        "uri": uri
                    }
                }

                if verbose:
                    print(f"\nRequest: {json.dumps(read_request, indent=2)}")

                server.process.stdin.write(json.dumps(read_request) + "\n")
                server.process.stdin.flush()
                response = server.process.stdout.readline()
                elapsed = time.time() - start_time

                if verbose:
                    print(f"Response: {response[:200]}")

                if not response:
                    fail_count += 1
                    print(f"  ‚ùå {uri}: No response ({elapsed:.2f}s)")
                    continue

                result = json.loads(response)
                if "error" in result:
                    fail_count += 1
                    error_msg = result['error'].get('message', 'Unknown error')
                    print(f"  ‚ùå {uri}: {error_msg} ({elapsed:.2f}s)")
                    if verbose:
                        print(f"     {result}")
                    continue

                # Validate resource content
                resource_data = result.get("result", {})
                contents = resource_data.get("contents", [])

                if not contents:
                    fail_count += 1
                    print(f"  ‚ùå {uri}: Empty contents ({elapsed:.2f}s)")
                    continue

                content = contents[0]  # MCP resources return array of content items

                # Validate MIME type
                expected_mime = test_config.get("expected_mime_type", "text/plain")
                actual_mime = content.get("mimeType", "text/plain")

                if expected_mime != actual_mime:
                    print(f"  ‚ö†Ô∏è  {uri}: MIME type mismatch (expected {expected_mime}, got {actual_mime})")

                # Validate content based on type
                validation = test_config.get("content_validation", {})
                content_type = validation.get("type", "text")

                if content_type == "text":
                    text = content.get("text", "")
                    min_len = validation.get("min_length", 0)
                    max_len = validation.get("max_length", float('inf'))

                    if len(text) < min_len:
                        fail_count += 1
                        print(f"  ‚ùå {uri}: Content too short ({len(text)} < {min_len}) ({elapsed:.2f}s)")
                        continue

                    if len(text) > max_len:
                        fail_count += 1
                        print(f"  ‚ùå {uri}: Content too long ({len(text)} > {max_len}) ({elapsed:.2f}s)")
                        continue

                elif content_type == "json":
                    # Parse and validate JSON content
                    text = content.get("text", "")
                    try:
                        json_data = json.loads(text)

                        # Validate against schema if provided
                        if "schema" in validation and validation["schema"]:
                            from jsonschema import validate as validate_schema
                            validate_schema(json_data, validation["schema"])

                    except json.JSONDecodeError as e:
                        fail_count += 1
                        print(f"  ‚ùå {uri}: Invalid JSON content ({e}) ({elapsed:.2f}s)")
                        continue
                    except Exception as e:
                        fail_count += 1
                        print(f"  ‚ùå {uri}: Schema validation failed ({e}) ({elapsed:.2f}s)")
                        continue

                elif content_type == "blob":
                    blob = content.get("blob", "")
                    if not blob:
                        fail_count += 1
                        print(f"  ‚ùå {uri}: Empty blob content ({elapsed:.2f}s)")
                        continue

                success_count += 1
                print(f"  ‚úÖ {uri} ({elapsed:.2f}s)")

                request_id += 1

            except Exception as e:
                fail_count += 1
                print(f"  ‚ùå {uri_pattern}: {e}")
                if verbose:
                    import traceback
                    print(f"     {traceback.format_exc()}")

        print(f"\nüìä Resource Test Results: {success_count}/{len(test_resources)} passed")
        return fail_count == 0

    except Exception as e:
        print(f"‚ùå Resource test execution failed: {e}")
        if verbose:
            import traceback
            print(traceback.format_exc())
        return False
```

**Integration into `main()`:**

```python
def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(...)

    # Add new arguments
    parser.add_argument(
        "--resources-only",
        action="store_true",
        help="Run only resource tests (skip tool tests)"
    )
    parser.add_argument(
        "--skip-resources",
        action="store_true",
        help="Skip resource tests (run only tool tests)"
    )

    args = parser.parse_args()

    # ... existing setup code ...

    try:
        # Run tool tests (unless --resources-only)
        tool_success = True
        if not args.resources_only:
            if server:
                tool_success = run_tests_stdio(server, TEST_CONFIG_PATH, tools, args.verbose)
            else:
                print("‚ùå No server available for testing")
                tool_success = False

        # Run resource tests (unless --skip-resources)
        resource_success = True
        if not args.skip_resources:
            if server:
                resource_success = run_resource_tests_stdio(
                    server, TEST_CONFIG_PATH, None, args.verbose
                )
            else:
                print("‚ùå No server available for resource testing")
                resource_success = False

        # Combined success
        overall_success = tool_success and resource_success

        # Show logs if requested
        if args.logs and server:
            server.logs()

        sys.exit(0 if overall_success else 1)

    finally:
        # ... existing cleanup code ...
```

#### 3. `scripts/mcp-test.py` Additions (HTTP Transport)

**New Method in `MCPTester` class:**

```python
def list_resources(self) -> List[Dict[str, Any]]:
    """List available resources from MCP server."""
    self._log("Querying available resources...")

    result = self._make_request("resources/list")
    resources = result.get("resources", [])

    self._log(f"‚úÖ Found {len(resources)} resources")
    return resources

def read_resource(self, uri: str) -> Dict[str, Any]:
    """Read a specific resource."""
    self._log(f"Reading resource: {uri}")

    params = {"uri": uri}
    result = self._make_request("resources/read", params)

    self._log(f"‚úÖ Resource {uri} read successfully")
    return result
```

**New Test Function:**

```python
def run_resources_test(
    tester: MCPTester,
    config: Dict[str, Any],
    specific_resource: Optional[str] = None
) -> bool:
    """Run comprehensive resources test."""
    test_resources = config.get("test_resources", {})

    if specific_resource:
        if specific_resource not in test_resources:
            print(f"‚ùå Resource '{specific_resource}' not found in test config")
            return False
        test_resources = {specific_resource: test_resources[specific_resource]}

    success_count = 0
    total_count = len(test_resources)

    print(f"\nüóÇÔ∏è  Running resources test ({total_count} resources)...")

    # Similar implementation to run_resource_tests_stdio but over HTTP
    # ... implementation details ...

    print(f"\nüìä Resource Test Results: {success_count}/{total_count} resources passed")
    return success_count == total_count
```

### Test Configuration Format

**Extended `mcp-test.yaml` structure:**

```yaml
_generated_by: "scripts/mcp-list.py - Auto-generated test configuration"
_note: "Edit test cases below to customize arguments and validation"

environment:
  AWS_PROFILE: "default"
  AWS_DEFAULT_REGION: "us-east-1"
  QUILT_CATALOG_DOMAIN: ""
  QUILT_DEFAULT_BUCKET: ""

# Existing tool tests
test_tools:
  catalog_configure:
    description: "Configure Quilt catalog URL..."
    idempotent: false
    arguments:
      catalog_url: "https://demo.quiltdata.com"
    response_schema:
      type: "object"
      properties:
        content:
          type: "array"

# NEW: Resource tests
test_resources:
  "quilt://status":
    description: "System status and health information"
    idempotent: true
    uri: "quilt://status"
    uri_variables: {}
    expected_mime_type: "application/json"
    content_validation:
      type: "json"
      min_length: 10
      max_length: 10000
      schema:
        type: "object"
        required: ["status", "version"]
        properties:
          status:
            type: "string"
            enum: ["ok", "error"]
          version:
            type: "string"

  "quilt://config/{key}":
    description: "Configuration value access"
    idempotent: true
    uri: "quilt://config/{key}"
    uri_variables:
      key: "catalog_url"  # Example key to test
    expected_mime_type: "text/plain"
    content_validation:
      type: "text"
      min_length: 1
      max_length: 1000

  "quilt://recent-packages":
    description: "List of recently accessed packages"
    idempotent: true
    uri: "quilt://recent-packages"
    uri_variables: {}
    expected_mime_type: "application/json"
    content_validation:
      type: "json"
      min_length: 2  # At least "[]"
      max_length: 100000
      schema:
        type: "array"
        items:
          type: "object"
          required: ["package_name", "timestamp"]

test_config:
  timeout: 30
  retry_attempts: 2
  fail_fast: false
```

### Output Format

**Unified test output:**

```
===üß™ Running MCP server integration tests (idempotent only)...
üìã Selected 22 tools for testing
üìã Found 5 resources for testing
üöÄ Starting MCP server in Docker (stdio transport)...
‚úÖ Container started with stdio transport

üß™ Running MCP tool tests (stdio)...
   Config: /Users/ernest/GitHub/quilt-mcp-server/scripts/tests/mcp-test.yaml
   Testing 22 tools
  ‚úÖ catalog_configure (0.25s)
  ‚úÖ catalog_uri (0.18s)
  ‚úÖ bucket_object_fetch (0.42s)
  ... (all 22 tools)

üìä Tool Test Results: 22/22 passed

üóÇÔ∏è  Running MCP resource tests (stdio)...
   Config: /Users/ernest/GitHub/quilt-mcp-server/scripts/tests/mcp-test.yaml
üìã Server provides 5 resources
  ‚úÖ quilt://status (0.15s)
  ‚úÖ quilt://config/catalog_url (0.12s)
  ‚úÖ quilt://recent-packages (0.23s)
  ‚úÖ quilt://buckets (0.31s)
  ‚úÖ quilt://auth-status (0.19s)

üìä Resource Test Results: 5/5 passed

‚úÖ All tests passed!
   Tools: 22/22
   Resources: 5/5
   Total: 27/27
```

## Implementation Plan

### Phase 1: Configuration Extension (Day 1)

**Goal:** Extend `mcp-list.py` to generate resource test configuration

**Tasks:**
1. Modify `generate_test_yaml()` to add `test_resources` section
2. Detect URI template variables from patterns
3. Infer content types and MIME types
4. Add sensible validation defaults
5. Test configuration generation

**Success Criteria:**
- `mcp-test.yaml` includes both `test_tools` and `test_resources`
- Resource URIs correctly extracted
- Template variables identified
- Manual configuration points marked

**Deliverables:**
- Updated `scripts/mcp-list.py`
- Sample `mcp-test.yaml` with resources
- Documentation of configuration format

### Phase 2: Stdio Transport Testing (Day 2)

**Goal:** Implement resource testing in `test_mcp.py`

**Tasks:**
1. Add `run_resource_tests_stdio()` function
2. Implement `resources/list` protocol call
3. Implement `resources/read` protocol call
4. Add content validation logic (text, JSON, blob)
5. Add schema validation for JSON content
6. Integrate into `main()` orchestration
7. Add CLI arguments (--resources-only, --skip-resources)

**Success Criteria:**
- Resource tests execute successfully via stdio
- Content validation works for all types
- Error handling robust and informative
- Test results clearly reported

**Deliverables:**
- Updated `scripts/tests/test_mcp.py`
- Working resource test execution
- Test output examples

### Phase 3: HTTP Transport Testing (Day 3)

**Goal:** Add resource testing to `mcp-test.py`

**Tasks:**
1. Add `list_resources()` method to `MCPTester`
2. Add `read_resource()` method to `MCPTester`
3. Implement `run_resources_test()` function
4. Add CLI arguments for resource testing
5. Test SSE format handling for resources
6. Integration with existing test framework

**Success Criteria:**
- Resource tests work over HTTP transport
- Compatible with SSE response format
- Parallel testing support
- Error handling consistent with tools

**Deliverables:**
- Updated `scripts/mcp-test.py`
- HTTP resource testing working
- Usage documentation

### Phase 4: Documentation & Integration (Day 4)

**Goal:** Complete documentation and CI/CD integration

**Tasks:**
1. Update test suite README
2. Document resource test configuration format
3. Add troubleshooting guide for resource tests
4. Update `make test-scripts` to run both tests
5. Add GitHub Actions workflow updates
6. Create examples for common resource patterns

**Success Criteria:**
- Complete documentation available
- CI/CD integration working
- Examples cover common use cases
- Troubleshooting guide helpful

**Deliverables:**
- Updated README files
- CI/CD workflow changes
- Example configurations
- Troubleshooting guide

## Testing Strategy

### Unit Tests

**New Test Files:**
1. `tests/test_resource_testing.py` - Unit tests for resource test logic
2. `tests/test_mcp_list_resources.py` - Tests for resource metadata extraction

**Test Coverage:**
- URI pattern parsing and variable substitution
- Content validation logic (text, JSON, blob)
- Schema validation error handling
- MIME type checking
- Resource discovery and listing

### Integration Tests

**Test Scenarios:**
1. **Basic Resource Reading**
   - Read simple static resource (`quilt://status`)
   - Validate content structure
   - Check MIME type

2. **Templated URI Handling**
   - Resource with single variable (`quilt://config/{key}`)
   - Variable substitution correct
   - Multiple test cases per template

3. **Content Type Validation**
   - Text content with length checks
   - JSON content with schema validation
   - Blob content existence checks

4. **Error Scenarios**
   - Invalid URI format
   - Non-existent resource
   - Malformed content
   - Schema validation failures

5. **Performance Testing**
   - All resources read in < 2 minutes
   - Parallel reading where applicable
   - Timeout handling

### End-to-End Tests

**Full Workflow:**
```bash
# Generate configuration with resources
make mcp-list

# Verify resource section exists
grep -q "test_resources:" scripts/tests/mcp-test.yaml

# Run full test suite (tools + resources)
make test-scripts

# Run only resource tests
python scripts/tests/test_mcp.py --resources-only

# Run specific resource test
python scripts/mcp-test.py http://localhost:8765/mcp \
    --test-resource "quilt://status"
```

## Success Criteria

### Quantitative Metrics

- [ ] **Coverage:** 100% of registered resources have test cases
- [ ] **Execution Time:** Resource tests complete within 30 seconds
- [ ] **Pass Rate:** 100% of resources pass validation
- [ ] **Maintainability:** Zero manual configuration for default resources
- [ ] **Documentation:** 100% of resource test features documented

### Qualitative Metrics

- [ ] **Developer Experience:** Easy to add new resource tests
- [ ] **Error Messages:** Clear, actionable failure messages
- [ ] **Integration:** Seamless with existing tool tests
- [ ] **Reliability:** No flaky or intermittent failures
- [ ] **Observability:** Clear visibility into what's being tested

## Risk Assessment

### Technical Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| Resource protocol differs from tools | High | Low | Reference MCP spec, test thoroughly |
| Content validation too strict | Medium | Medium | Start permissive, tighten over time |
| URI template parsing breaks | High | Low | Use regex with comprehensive tests |
| Performance degradation | Medium | Low | Parallel reading, timeouts |
| False positives in validation | High | Medium | Multiple validation modes, verbose output |

### Process Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| Configuration complexity grows | Medium | High | Keep defaults simple, document well |
| Manual test maintenance burden | High | Medium | Auto-generate from code introspection |
| CI/CD pipeline slowdown | Medium | Low | Run in parallel with tool tests |
| Breaking changes to MCP protocol | High | Low | Version-specific test configuration |

## Alternatives Considered

### Alternative 1: Separate Resource Test Script

**Approach:** Create `test_mcp_resources.py` as standalone script

**Pros:**
- Clear separation of concerns
- Easier to maintain independently
- Can evolve separately from tool tests

**Cons:**
- Duplicates Docker management code
- Two separate test runs required
- Harder to get unified pass/fail status
- More complex CI/CD integration

**Decision:** ‚ùå Rejected - Integration into existing script is cleaner

### Alternative 2: HTTP-Only Resource Testing

**Approach:** Only implement resource tests in `mcp-test.py` (HTTP transport)

**Pros:**
- Simpler implementation
- No stdio complexity
- Easier to debug

**Cons:**
- Inconsistent with tool testing approach
- Requires running server externally
- Loses Docker integration benefits
- Can't use in CI without extra setup

**Decision:** ‚ùå Rejected - Stdio transport is primary test method

### Alternative 3: Manual Resource Test Configuration

**Approach:** Manually maintain resource test cases in YAML

**Pros:**
- Full control over test cases
- Can add complex validation logic
- Custom test scenarios easily

**Cons:**
- High maintenance burden
- Prone to drift from actual resources
- Requires updates for every resource change
- Error-prone

**Decision:** ‚ùå Rejected - Auto-generation is core design principle

## Future Enhancements

### Short Term (Next Sprint)

1. **Resource Templates Library**
   - Common validation patterns for typical resources
   - Reusable schema definitions
   - Best practices for resource design

2. **Performance Profiling**
   - Measure resource read latency
   - Identify slow resources
   - Performance regression detection

3. **Enhanced Error Diagnostics**
   - Detailed failure analysis
   - Suggested fixes for common errors
   - Integration with MCP debug tools

### Medium Term (Next Quarter)

1. **Resource Mocking Framework**
   - Mock resources for testing tools that consume them
   - Configurable mock responses
   - Error scenario simulation

2. **Resource Contract Testing**
   - Verify resource contracts across versions
   - Breaking change detection
   - Consumer-driven contract tests

3. **Multi-Version Testing**
   - Test resources across MCP protocol versions
   - Backward compatibility validation
   - Migration path testing

### Long Term (Next 6 Months)

1. **Resource Performance Benchmarks**
   - Standard benchmark suite
   - Performance comparison across versions
   - Regression detection and alerting

2. **Automated Resource Documentation**
   - Generate resource documentation from tests
   - OpenAPI-style specs for resources
   - Interactive resource explorer

3. **Resource Ecosystem Tests**
   - Test resource interactions
   - Verify resource dependencies
   - End-to-end workflow validation

## Appendix

### A. MCP Resources Protocol Reference

**resources/list Request:**
```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "resources/list",
  "params": {}
}
```

**resources/list Response:**
```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "resources": [
      {
        "uri": "quilt://status",
        "name": "System Status",
        "description": "Current system status and health",
        "mimeType": "application/json"
      }
    ]
  }
}
```

**resources/read Request:**
```json
{
  "jsonrpc": "2.0",
  "id": 2,
  "method": "resources/read",
  "params": {
    "uri": "quilt://status"
  }
}
```

**resources/read Response:**
```json
{
  "jsonrpc": "2.0",
  "id": 2,
  "result": {
    "contents": [
      {
        "uri": "quilt://status",
        "mimeType": "application/json",
        "text": "{\"status\": \"ok\", \"version\": \"1.0.0\"}"
      }
    ]
  }
}
```

### B. Example Resource Test Cases

**Status Resource:**
```yaml
"quilt://status":
  description: "System status and health"
  idempotent: true
  uri: "quilt://status"
  expected_mime_type: "application/json"
  content_validation:
    type: "json"
    schema:
      type: "object"
      required: ["status", "version", "authenticated"]
      properties:
        status:
          type: "string"
          enum: ["ok", "degraded", "error"]
        version:
          type: "string"
          pattern: "^\\d+\\.\\d+\\.\\d+$"
        authenticated:
          type: "boolean"
```

**Config Resource:**
```yaml
"quilt://config/{key}":
  description: "Configuration value by key"
  idempotent: true
  uri: "quilt://config/{key}"
  uri_variables:
    key: "catalog_url"
  expected_mime_type: "text/plain"
  content_validation:
    type: "text"
    min_length: 1
    max_length: 500
```

**Binary Resource:**
```yaml
"quilt://logo":
  description: "Quilt logo image"
  idempotent: true
  uri: "quilt://logo"
  expected_mime_type: "image/png"
  content_validation:
    type: "blob"
    min_length: 100
    max_length: 1000000
```

### C. Validation Schema Examples

**Package List Schema:**
```json
{
  "type": "array",
  "items": {
    "type": "object",
    "required": ["package_name", "registry", "timestamp"],
    "properties": {
      "package_name": {
        "type": "string",
        "pattern": "^[a-zA-Z0-9_-]+/[a-zA-Z0-9_-]+$"
      },
      "registry": {
        "type": "string",
        "pattern": "^s3://[a-z0-9][a-z0-9.-]+$"
      },
      "timestamp": {
        "type": "string",
        "format": "date-time"
      },
      "top_hash": {
        "type": ["string", "null"]
      }
    }
  }
}
```

**Auth Status Schema:**
```json
{
  "type": "object",
  "required": ["authenticated", "catalog_url"],
  "properties": {
    "authenticated": {
      "type": "boolean"
    },
    "catalog_url": {
      "type": ["string", "null"]
    },
    "username": {
      "type": ["string", "null"]
    },
    "expires_at": {
      "type": ["string", "null"],
      "format": "date-time"
    }
  }
}
```

### D. Command Reference

**Generate test configuration with resources:**
```bash
python scripts/mcp-list.py
```

**Run all tests (tools + resources):**
```bash
make test-scripts
# OR
python scripts/tests/test_mcp.py
```

**Run only resource tests:**
```bash
python scripts/tests/test_mcp.py --resources-only
```

**Run only tool tests (skip resources):**
```bash
python scripts/tests/test_mcp.py --skip-resources
```

**Run specific resource test:**
```bash
python scripts/tests/test_mcp.py --resource "quilt://status"
```

**Verbose output for debugging:**
```bash
python scripts/tests/test_mcp.py --resources-only -v
```

**HTTP endpoint testing with resources:**
```bash
python scripts/mcp-test.py http://localhost:8765/mcp --list-resources
python scripts/mcp-test.py http://localhost:8765/mcp --resources-test
python scripts/mcp-test.py http://localhost:8765/mcp --test-resource "quilt://status"
```

---

**Status:** üìã SPECIFICATION COMPLETE
**Next Step:** Begin Phase 1 implementation (Configuration Extension)
**Author:** Claude Code
**Date:** 2025-11-12
